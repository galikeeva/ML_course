{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iLykei Lecture Series\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Introduction to Deep Learning\n",
    "\n",
    "# Project: MNIST by Simple Deep NN\n",
    "\n",
    "\n",
    "## Yuri Balasanov, &copy; iLykei 2018\n",
    "\n",
    "##### Main source: [Keras Documentation](https://github.com/keras-team/keras/tree/master/examples)\n",
    "\n",
    "This notebook shows how to train a simple deep NN on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep network solution\n",
    "\n",
    "This example of deep network architecture for MNIST data is based on Keras documentation.\n",
    "\n",
    "Set main parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, create train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape x_train:  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('Shape x_train: ',x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2], dtype=uint8)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (28, 28)\n",
      "Raw:  [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]]\n",
      "First label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = x_train[0]\n",
    "print('Shape: ',first_image.shape)\n",
    "print('Raw: ',first_image[:6,])\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "print('First label: ',y_train[0])\n",
    "\n",
    "plt.imshow(first_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten and normalize the train and test samples images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784) # each image as vector 784=28*28\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert class vectors to binary class matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row size of y_train:  (10,)\n",
      "y_train: \n",
      " [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "y_test: \n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('Row size of y_train: ',y_train[0].shape)\n",
    "print('y_train: \\n',y_train[:6])\n",
    "print('y_test: \\n',y_test[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "\n",
    "**Assignment 1**\n",
    "\n",
    "Create model with two hidden layers of 196 units with relu activation function, followed by 0.2 dropouts. Output has 10 units (`num_classes`) with softmax activation.\n",
    "Print model summary:\n",
    "\n",
    "_________________________________________________________________ <br>\n",
    "Layer (type)                 Output Shape              Param #    <br>\n",
    "================================================================= <br>\n",
    "dense_1 (Dense)              (None, 196)               153860     <br>\n",
    "_________________________________________________________________ <br>\n",
    "dropout_1 (Dropout)          (None, 196)               0          <br>\n",
    "_________________________________________________________________ <br>\n",
    "dense_2 (Dense)              (None, 196)               38612      <br>\n",
    "_________________________________________________________________ <br>\n",
    "dropout_2 (Dropout)          (None, 196)               0          <br>\n",
    "_________________________________________________________________ <br>\n",
    "dense_3 (Dense)              (None, 10)                1970       <br>\n",
    "================================================================= <br>\n",
    "Total params: 194,442 <br>\n",
    "Trainable params: 194,442 <br>\n",
    "Non-trainable params: 0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code: model and summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model architecture.\n",
    "\n",
    "![l3](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Data%20Mining%20and%20Predictive%20Analytics%2031009%2FLecture%20Deep%20Learning%2Fsimple_dense_mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n",
    "# Plot architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model using `categorical_crossentropy` as loss and `accuracy` as metrics. Try optimizers `RMSprop()` or `Adam`.\n",
    "Read [one of available sources](http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms) for more information about optimizers and their comparisons.\n",
    "\n",
    "\n",
    "Visualize initial weights of the first layer: it contains 196 units, each unit has $784=28 \\times 28$ inputs. So, each of 196 vectors of weights has 784 components and can be interpreted as image of size $28 \\times 28$. \n",
    "\n",
    "Reshaping these vectors into 196 arrays of shape (28,28) allows vizualizing the weights as (28,28) images in which intensity of a pixel corresponds to the size of weight.\n",
    "\n",
    "Show 25 weights vectors."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "w_init = model.layers[0].get_weights()[0]\n",
    "\n",
    "R, C = 5, 5  # rows, columns\n",
    "plt.figure(figsize=(R, C))\n",
    "for i in range(R*C):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(w_init[:,i].reshape((28, 28)), cmap='Greys', interpolation='nearest')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial weights are random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "\n",
    "Fit the model: \n",
    "\n",
    "* Inputs `x_train` and labels `y_train`\n",
    "* Call fitted model object `history`\n",
    "* Use parameters' values defined earlier:\n",
    "\n",
    "`batch_size = 128` <br>\n",
    "`epochs = 20` <br>\n",
    "\n",
    "* Define `validation_data` = (x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show keys of variables saved in `history`. Plot accuracy and validation accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylim((0.8,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check estimated weights and their shapes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Weights matrix: ',model.layers[0].get_weights()[0].shape)\n",
    "print('Bias vector: ',model.layers[0].get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize weights of the first layer and compare them with the initial weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w = model.layers[0].get_weights()[0]\n",
    "\n",
    "R, C = 5, 5  # rows, columns\n",
    "plt.figure(figsize=(R, C))\n",
    "for i in range(R*C):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(w[:,i].reshape((28, 28)), cmap='Greys', interpolation='nearest')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow network solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "\n",
    "**Assignment 2**\n",
    "\n",
    "Modify the model to `model1` with only 1 hidden layer with 100 units and `relu` activation. Print summary of the model.\n",
    "\n",
    "![l1](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Data%20Mining%20and%20Predictive%20Analytics%2031009%2FLecture%20Deep%20Learning%2Fsimple_dense_mnist1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "mpl.rcParams['figure.figsize'] = (7,7)  # plot sizes\n",
    "\n",
    "plot_model(model1, to_file='simple_dense_mnist1.png', show_shapes=True)\n",
    "plt.imshow(imageio.imread('simple_dense_mnist1.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "\n",
    "* Compile the model\n",
    "* Fit it\n",
    "* Evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n",
    "# Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n",
    "# Fit the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(history1.history.keys())\n",
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.ylim((0.8,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the trained weigths again."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_shallow = model1.layers[0].get_weights()[0]\n",
    "\n",
    "R, C = 5, 5  # rows, columns\n",
    "plt.figure(figsize=(R, C))\n",
    "for i in range(R*C):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(w_shallow[:,i].reshape((28, 28)), cmap='Greys', interpolation='nearest')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how the first 5 numbers from the test sample are predicted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Actual: \\n',y_test[:5],'\\n ')\n",
    "print('Predicted: \\n',np.around(np.array(model1.predict(x_test)[:5]), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to reduce number of units in the single hidden layer to make it less overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
